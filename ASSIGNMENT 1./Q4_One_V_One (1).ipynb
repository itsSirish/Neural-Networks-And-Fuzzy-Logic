{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q4_One V One.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q4 ONE VS ONE"
      ],
      "metadata": {
        "id": "bH_DRY7jpyPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MOUNTING THE DRIVE"
      ],
      "metadata": {
        "id": "fZvCLWpxgQpY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "q7RVnjw4a28m",
        "outputId": "38d628d7-6813-4986-e65e-da87096ddceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "oOyefUfygUnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "np.random.seed(0)\n",
        "import statistics"
      ],
      "metadata": {
        "id": "UNhkaVIpa8Pw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "qFIaJKPya8NN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING SIGMOID FUNCTION"
      ],
      "metadata": {
        "id": "1xpA5pTpgWNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  x = x.astype(float)\n",
        "  z = np.exp(-x)\n",
        "  sig = 1 / (1 + z)\n",
        "  return sig"
      ],
      "metadata": {
        "id": "w22h9Iqwa8KB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING SET FUNCTION"
      ],
      "metadata": {
        "id": "uoylEoJjgYpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set(y,k,j):\n",
        "    for i in range(len(y)):\n",
        "        if(y[i]>=0.5):\n",
        "            y[i] = j\n",
        "        if(y[i]<0.5):\n",
        "            y[i] = k\n",
        "    return y"
      ],
      "metadata": {
        "id": "oGniMBZ9bCS1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING GRADIENT DESCENT FUNCTIONS"
      ],
      "metadata": {
        "id": "6s0Bk1v5gZ__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_gradient_descent_l1(X,y,w,alpha,iters,lamb):\n",
        "  \n",
        "  cost_history = np.zeros(iters) # cost function for each iteration\n",
        "  \n",
        "  #initalize our cost history list to store the cost function on every iteration\n",
        "  \n",
        "  for i in range(iters):\n",
        "    z = np.dot(X,w.T)\n",
        "    hypothesis = sigmoid(z)\n",
        "    w = w -  alpha * np.dot((hypothesis-y), X) - ((alpha*lamb/2)*np.sign(w))#weight updation\n",
        "  \n",
        "  return w"
      ],
      "metadata": {
        "id": "YZpod32zL5e5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_gradient_descent_l2(X,y,w,alpha,iters,lamb):\n",
        "  \n",
        "  cost_history = np.zeros(iters) # cost function for each iteration\n",
        "  \n",
        "  #initalize our cost history list to store the cost function on every iteration\n",
        "  \n",
        "  for i in range(iters):\n",
        "    z = np.dot(X,w.T)\n",
        "    hypothesis = sigmoid(z)\n",
        "    w = w*(1-alpha*lamb) -  alpha * np.dot((hypothesis-y), X) #weight updation\n",
        "  \n",
        "  return w"
      ],
      "metadata": {
        "id": "M0p9TROKL5W0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_gradient_descent(X,y,w,alpha,iters):\n",
        "  \n",
        "  cost_history = np.zeros(iters) # cost function for each iteration\n",
        "  \n",
        "  #initalize our cost history list to store the cost function on every iteration\n",
        "  \n",
        "  for i in range(iters):\n",
        "    z = np.dot(X,w.T)\n",
        "    hypothesis = sigmoid(z)\n",
        "    w = w -  alpha * np.dot((hypothesis-y), X) #weight updation\n",
        "  \n",
        "  return w"
      ],
      "metadata": {
        "id": "9HyHJ480bDbE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING THE DATA"
      ],
      "metadata": {
        "id": "TZsDVfNzgdQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/drive/MyDrive/nnfl data/data.xlsx',header=None)"
      ],
      "metadata": {
        "id": "Fs2UHJyMbDY5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datan=data.values\n",
        "X=datan[:,0:datan.shape[1]-1]\n",
        "y=datan[:,datan.shape[1]-1]\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QPhHIirNbDWw",
        "outputId": "5fc56098-068a-43b4-9305-bd61950580ff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3412, 61)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPLITTING THE DATA INTO TRAINING, VALIDATION AND TESTING I.E. HOLDOUT VALIDATION"
      ],
      "metadata": {
        "id": "4_3JEOkIgffk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle = True, random_state = 60)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.125, shuffle = True, random_state = 60)"
      ],
      "metadata": {
        "id": "bsJTg-zabKAU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NORMALISING THE DATA AND ADDING BIAS VECTOR"
      ],
      "metadata": {
        "id": "_K2y9nAVgmJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m=X_train.shape[0] \n",
        "n=X_test.shape[0]\n",
        "\n",
        "qq = np.ones([n, 1])\n",
        "\n",
        "xmin1 = np.min(X_test, axis = 0) \n",
        "xmax1 = np.max(X_test, axis = 0) \n",
        "\n",
        "X_test = (X_test- xmin1)/(xmax1-xmin1)\n",
        "\n",
        "X_test = np.append(qq,X_test, axis=1)"
      ],
      "metadata": {
        "id": "gvKGPk9cbMTZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xmin = np.min(X_train, axis = 0) \n",
        "xmax = np.max(X_train, axis = 0) \n",
        "\n",
        "X_train = (X_train- xmin)/(xmax-xmin)\n"
      ],
      "metadata": {
        "id": "v1kAWwtUbPJ9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp = np.ones([m, 1])\n",
        "X_train = np.append(pp,X_train, axis=1) #Column of ones \n",
        "\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ErDJgzvfbRLf",
        "outputId": "1d1afe95-44a6-4330-b148-4ebc9dd81063"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.4565523  0.70925588 ... 0.52205576 0.84817498 0.86645165]\n",
            " [1.         0.34247347 0.52862044 ... 0.20327721 0.81558568 0.71125864]\n",
            " [1.         0.59779369 0.24443946 ... 0.6853999  0.82794782 0.64855454]\n",
            " ...\n",
            " [1.         0.74693149 0.34984461 ... 0.21043456 0.84001243 0.84605655]\n",
            " [1.         0.23788388 0.25948086 ... 0.43523629 0.71647965 0.62122422]\n",
            " [1.         0.64374366 0.5491812  ... 0.5910701  0.8530399  0.66566898]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr=X_train\n",
        "y_tr=y_train"
      ],
      "metadata": {
        "id": "JxmDL3AimvMT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_tr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zPc0ipkbehxE",
        "outputId": "29c81f93-712d-4b0c-a472-917b2a7bc839"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3. 2. 3. ... 4. 2. 3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAKING MODELS FOR DIFFERENT OVE VS ONE CASES"
      ],
      "metadata": {
        "id": "RgcI1WQjg6de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1_tr = [] # class 1 vs class 2\n",
        "y2_tr = [] # class 1 vs class 3\n",
        "y3_tr = [] # class 1 vs class 4\n",
        "y4_tr = [] # class 2 vs class 3\n",
        "y5_tr = [] # class 2 vs class 4\n",
        "y6_tr = [] # class 3 vs class 4\n",
        "x1_tr = [] \n",
        "x2_tr = []  \n",
        "x3_tr = [] \n",
        "x4_tr = []\n",
        "x5_tr = []\n",
        "x6_tr = []\n"
      ],
      "metadata": {
        "id": "PWFzu29sf-2n"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADDING VALUES TO EACH ONE VS ONE CLASS LIST"
      ],
      "metadata": {
        "id": "IwvgTpenhAf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_tr)):\n",
        "    if(y_tr[i] != 3 and y_tr[i] != 4 ):\n",
        "        y1_tr.append(y_tr[i])\n",
        "        x1_tr.append(x_tr[i])\n",
        "    if(y_tr[i] != 2 and y_tr[i] != 4):\n",
        "        y2_tr.append(y_tr[i])\n",
        "        x2_tr.append(x_tr[i])\n",
        "    if(y_tr[i] != 2 and y_tr[i] != 3):\n",
        "        y3_tr.append(y_tr[i])\n",
        "        x3_tr.append(x_tr[i])\n",
        "    if(y_tr[i] != 1 and y_tr[i] != 4):\n",
        "        y4_tr.append(y_tr[i])\n",
        "        x4_tr.append(x_tr[i])\n",
        "    if(y_tr[i] != 1 and y_tr[i] != 3):\n",
        "        y5_tr.append(y_tr[i])\n",
        "        x5_tr.append(x_tr[i])\n",
        "    if(y_tr[i] != 1 and y_tr[i] != 2):\n",
        "        y6_tr.append(y_tr[i])\n",
        "        x6_tr.append(x_tr[i])"
      ],
      "metadata": {
        "id": "rB1DYvdSeM94"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1_tr = np.asarray(x1_tr)\n",
        "x2_tr = np.asarray(x2_tr)\n",
        "x3_tr = np.asarray(x3_tr)\n",
        "x4_tr = np.asarray(x4_tr)\n",
        "x5_tr = np.asarray(x5_tr)\n",
        "x6_tr = np.asarray(x6_tr)\n",
        "\n"
      ],
      "metadata": {
        "id": "fqp3R1z7l6IC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING LOW AND HIGH FOR EACH CLASS CASE"
      ],
      "metadata": {
        "id": "x07Qv5c6hHrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y1_tr)):\n",
        "    if y1_tr[i] == 1:\n",
        "        y1_tr[i] = 0\n",
        "    else:\n",
        "        y1_tr[i] = 1 \n",
        "\n",
        "for i in range(len(y2_tr)):\n",
        "    if y2_tr[i] == 1:\n",
        "        y2_tr[i] = 0\n",
        "    else:\n",
        "        y2_tr[i] = 1 \n",
        "\n",
        "for i in range(len(y3_tr)):\n",
        "    if y3_tr[i] == 1:\n",
        "        y3_tr[i] = 0\n",
        "    else:\n",
        "        y3_tr[i] = 1\n",
        "for i in range(len(y4_tr)):\n",
        "    if y4_tr[i] == 2:\n",
        "        y4_tr[i] = 0\n",
        "    else:\n",
        "        y4_tr[i] = 1 \n",
        "for i in range(len(y5_tr)):\n",
        "    if y5_tr[i] == 2:\n",
        "        y5_tr[i] = 0\n",
        "    else:\n",
        "        y5_tr[i] = 1 \n",
        "for i in range(len(y6_tr)):\n",
        "    if y6_tr[i] == 3:\n",
        "        y6_tr[i] = 0\n",
        "    else:\n",
        "        y6_tr[i] = 1 "
      ],
      "metadata": {
        "id": "P9JTv4tWl92a"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTING BATCH GRADIENT DESCENT FOR MULTICLASS ONE VS ONE"
      ],
      "metadata": {
        "id": "-NYDmxfJhL3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha=0.008\n",
        "iters=1000\n",
        "w1= np.zeros((x1_tr.shape[1])) ###weight initialization\n",
        "w_m1 = batch_gradient_descent(x1_tr,y1_tr,w1,alpha,iters)\n",
        "y_p1 = np.dot(X_test,w_m1.T)\n",
        "y_p1 = set(y_p1,1,2)\n",
        "\n",
        "\n",
        "w2= np.zeros((x2_tr.shape[1])) ###weight initialization\n",
        "w_m2 = batch_gradient_descent(x2_tr,y2_tr,w2,alpha,iters)\n",
        "y_p2 = np.dot(X_test,w_m2.T)\n",
        "y_p2 = set(y_p2,1,3)\n",
        "\n",
        "\n",
        "w3= np.zeros((x3_tr.shape[1])) ###weight initialization\n",
        "w_m3 = batch_gradient_descent(x3_tr,y3_tr,w3,alpha,iters)\n",
        "y_p3 = np.dot(X_test,w_m3.T)\n",
        "y_p3 = set(y_p3,1,4)\n",
        "\n",
        "\n",
        "w4= np.zeros((x4_tr.shape[1])) ###weight initialization\n",
        "w_m4 = batch_gradient_descent(x4_tr,y4_tr,w4,alpha,iters)\n",
        "y_p4 = np.dot(X_test,w_m4.T)\n",
        "y_p4 = set(y_p4,2,3)\n",
        "\n",
        "\n",
        "w5= np.zeros((x5_tr.shape[1])) ###weight initialization\n",
        "w_m5 = batch_gradient_descent(x5_tr,y5_tr,w5,alpha,iters)\n",
        "y_p5 = np.dot(X_test,w_m5.T)\n",
        "y_p5 = set(y_p5,2,4)\n",
        "\n",
        "\n",
        "w6= np.zeros((x6_tr.shape[1])) ###weight initialization\n",
        "w_m6 = batch_gradient_descent(x6_tr,y6_tr,w6,alpha,iters)\n",
        "y_p6 = np.dot(X_test,w_m6.T)\n",
        "y_p6 = set(y_p6,3,4)\n"
      ],
      "metadata": {
        "id": "c75RQom-bYUA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING MODE FUNCTION"
      ],
      "metadata": {
        "id": "3EQKGwI1hUGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def my_mode(sample):\n",
        "  return Counter(sample).most_common(1)[0][0]\n"
      ],
      "metadata": {
        "id": "AyMkK0Iu7vrL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CALCULATING MODE OF PREDICTED OUTPUT"
      ],
      "metadata": {
        "id": "BvK3BLG1hVqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mode\n",
        "\n",
        "cval = [0 for i in range(len(y_test))]\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  \n",
        "  k=[y_p1[i],y_p2[i],y_p3[i],y_p4[i],y_p5[i],y_p6[i]]\n",
        "\n",
        "  cval[i]=my_mode(k)\n"
      ],
      "metadata": {
        "id": "JsuarOvvbh9o"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERATING CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "shXxgaTmhbZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(cval)):\n",
        "    if (cval[i] == 0):\n",
        "        cval[i] = 'None'\n",
        "\n",
        "print(cval)\n",
        "y_actual = pd.Series(y_test, name='Actual')\n",
        "y_pred = pd.Series(cval, name='Predicted')\n",
        "confmat = pd.crosstab(y_actual, y_pred)\n",
        "print(confmat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wvq5lkBtsvHX",
        "outputId": "09a35d2f-ea2c-4c42-8d64-9808de93277d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0]\n",
            "Predicted  1.0  2.0  3.0  4.0\n",
            "Actual                       \n",
            "1.0          3   19  122    7\n",
            "2.0          4   23  141    5\n",
            "3.0          8   39  128   15\n",
            "4.0          4   21  136    8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINDING ACCURACY"
      ],
      "metadata": {
        "id": "TzENk5Slhf0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "confmat = np.asarray(confmat)\n",
        "Acc = (confmat[0][0] + confmat[1][1] + confmat[2][2])/sum(sum(confmat))\n",
        "Acc1 = confmat[0][0]/sum(confmat[0])\n",
        "Acc2 = confmat[1][1]/sum(confmat[1])\n",
        "Acc3 = confmat[2][2]/sum(confmat[2])\n",
        "Acc4 = confmat[3][3]/sum(confmat[3])\n",
        "print('Overall Accuracy : ' + str(Acc))\n",
        "print('Accuracy of class 1 : ' + str(Acc1))\n",
        "print('Accuracy of class 2 : ' + str(Acc2))\n",
        "print('Accuracy of class 3 : ' + str(Acc3))\n",
        "print('Accuracy of class 4 : ' + str(Acc4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cVq3lCEJeLPX",
        "outputId": "484570e9-43dd-48cb-fb89-c47f6ef2fbe0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy : 0.22547584187408493\n",
            "Accuracy of class 1 : 0.019867549668874173\n",
            "Accuracy of class 2 : 0.1329479768786127\n",
            "Accuracy of class 3 : 0.6736842105263158\n",
            "Accuracy of class 4 : 0.047337278106508875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTING BATCH GRADIENT DESCENT FOR MULTICLASS ONE VS ONE WITH L1 NORM"
      ],
      "metadata": {
        "id": "2Oqc99AFhmAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha=0.008\n",
        "iters=1000\n",
        "lamb=1\n",
        "w1= np.zeros((x1_tr.shape[1])) ###weight initialization\n",
        "w_m1 = batch_gradient_descent_l1(x1_tr,y1_tr,w1,alpha,iters,lamb)\n",
        "y_p1 = np.dot(X_test,w_m1.T)\n",
        "y_p1 = set(y_p1,1,2)\n",
        "\n",
        "\n",
        "w2= np.zeros((x2_tr.shape[1])) ###weight initialization\n",
        "w_m2 = batch_gradient_descent_l1(x2_tr,y2_tr,w2,alpha,iters,lamb)\n",
        "y_p2 = np.dot(X_test,w_m2.T)\n",
        "y_p2 = set(y_p2,1,3)\n",
        "\n",
        "\n",
        "w3= np.zeros((x3_tr.shape[1])) ###weight initialization\n",
        "w_m3 = batch_gradient_descent_l1(x3_tr,y3_tr,w3,alpha,iters,lamb)\n",
        "y_p3 = np.dot(X_test,w_m3.T)\n",
        "y_p3 = set(y_p3,1,4)\n",
        "\n",
        "\n",
        "w4= np.zeros((x4_tr.shape[1])) ###weight initialization\n",
        "w_m4 = batch_gradient_descent_l1(x4_tr,y4_tr,w4,alpha,iters,lamb)\n",
        "y_p4 = np.dot(X_test,w_m4.T)\n",
        "y_p4 = set(y_p4,2,3)\n",
        "\n",
        "\n",
        "w5= np.zeros((x5_tr.shape[1])) ###weight initialization\n",
        "w_m5 = batch_gradient_descent_l1(x5_tr,y5_tr,w5,alpha,iters,lamb)\n",
        "y_p5 = np.dot(X_test,w_m5.T)\n",
        "y_p5 = set(y_p5,2,4)\n",
        "\n",
        "\n",
        "w6= np.zeros((x6_tr.shape[1])) ###weight initialization\n",
        "w_m6 = batch_gradient_descent_l1(x6_tr,y6_tr,w6,alpha,iters,lamb)\n",
        "y_p6 = np.dot(X_test,w_m6.T)\n",
        "y_p6 = set(y_p6,3,4)"
      ],
      "metadata": {
        "id": "XDslnVSlhpc7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING MODE FUNCTION"
      ],
      "metadata": {
        "id": "fpj3rm0tho5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def my_mode(sample):\n",
        "  return Counter(sample).most_common(1)[0][0]"
      ],
      "metadata": {
        "id": "FsIRpTQqN-HY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CALCULATING MODE OF PREDICTED OUTPUT"
      ],
      "metadata": {
        "id": "nhaGMf00hrDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mode\n",
        "\n",
        "cval = [0 for i in range(len(y_test))]\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  k=[y_p1[i],y_p2[i],y_p3[i],y_p4[i],y_p5[i],y_p6[i]]\n",
        "\n",
        "  cval[i]=my_mode(k)"
      ],
      "metadata": {
        "id": "iFXCp2AVOBB9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERATING CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "yGsUQrW5hsy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(cval)):\n",
        "    if (cval[i] == 0):\n",
        "        cval[i] = 'None'\n",
        "\n",
        "print(cval)\n",
        "y_actual = pd.Series(y_test, name='Actual')\n",
        "y_pred = pd.Series(cval, name='Predicted')\n",
        "confmat = pd.crosstab(y_actual, y_pred)\n",
        "print(confmat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lm-4DQ6_OCrM",
        "outputId": "2a5bc43d-8529-4163-9bd1-74007b0d65dd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0]\n",
            "Predicted  1.0  2.0  3.0  4.0\n",
            "Actual                       \n",
            "1.0          3   14  129    5\n",
            "2.0          3   19  147    4\n",
            "3.0          6   32  141   11\n",
            "4.0          4   19  141    5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINDING ACCURACY"
      ],
      "metadata": {
        "id": "Cw8Z9T3Qhuti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "confmat = np.asarray(confmat)\n",
        "Acc = (confmat[0][0] + confmat[1][1] + confmat[2][2])/sum(sum(confmat))\n",
        "Acc1 = confmat[0][0]/sum(confmat[0])\n",
        "Acc2 = confmat[1][1]/sum(confmat[1])\n",
        "Acc3 = confmat[2][2]/sum(confmat[2])\n",
        "Acc4 = confmat[3][3]/sum(confmat[3])\n",
        "print('Overall Accuracy : ' + str(Acc))\n",
        "print('Accuracy of class 1 : ' + str(Acc1))\n",
        "print('Accuracy of class 2 : ' + str(Acc2))\n",
        "print('Accuracy of class 3 : ' + str(Acc3))\n",
        "print('Accuracy of class 4 : ' + str(Acc4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fwN6Mpv2OFLi",
        "outputId": "9b70a1ed-d9ab-4185-e147-fd05a97eb62b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy : 0.23865300146412885\n",
            "Accuracy of class 1 : 0.019867549668874173\n",
            "Accuracy of class 2 : 0.10982658959537572\n",
            "Accuracy of class 3 : 0.7421052631578947\n",
            "Accuracy of class 4 : 0.029585798816568046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTING BATCH GRADIENT DESCENT FOR MULTICLASS ONE VS ONE WITH L2 NORM"
      ],
      "metadata": {
        "id": "v7YJROm7hzS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha=0.001\n",
        "iters=1000\n",
        "lamb=0.008\n",
        "w1= np.zeros((x1_tr.shape[1])) ###weight initialization\n",
        "w_m1 = batch_gradient_descent_l2(x1_tr,y1_tr,w1,alpha,iters,lamb)\n",
        "y_p1 = np.dot(X_test,w_m1.T)\n",
        "y_p1 = set(y_p1,1,2)\n",
        "\n",
        "\n",
        "w2= np.zeros((x2_tr.shape[1])) ###weight initialization\n",
        "w_m2 = batch_gradient_descent_l2(x2_tr,y2_tr,w2,alpha,iters,lamb)\n",
        "y_p2 = np.dot(X_test,w_m2.T)\n",
        "y_p2 = set(y_p2,1,3)\n",
        "\n",
        "\n",
        "w3= np.zeros((x3_tr.shape[1])) ###weight initialization\n",
        "w_m3 = batch_gradient_descent_l2(x3_tr,y3_tr,w3,alpha,iters,lamb)\n",
        "y_p3 = np.dot(X_test,w_m3.T)\n",
        "y_p3 = set(y_p3,1,4)\n",
        "\n",
        "\n",
        "w4= np.zeros((x4_tr.shape[1])) ###weight initialization\n",
        "w_m4 = batch_gradient_descent_l2(x4_tr,y4_tr,w4,alpha,iters,lamb)\n",
        "y_p4 = np.dot(X_test,w_m4.T)\n",
        "y_p4 = set(y_p4,2,3)\n",
        "\n",
        "\n",
        "w5= np.zeros((x5_tr.shape[1])) ###weight initialization\n",
        "w_m5 = batch_gradient_descent_l2(x5_tr,y5_tr,w5,alpha,iters,lamb)\n",
        "y_p5 = np.dot(X_test,w_m5.T)\n",
        "y_p5 = set(y_p5,2,4)\n",
        "\n",
        "\n",
        "w6= np.zeros((x6_tr.shape[1])) ###weight initialization\n",
        "w_m6 = batch_gradient_descent_l2(x6_tr,y6_tr,w6,alpha,iters,lamb)\n",
        "y_p6 = np.dot(X_test,w_m6.T)\n",
        "y_p6 = set(y_p6,3,4)"
      ],
      "metadata": {
        "id": "p0mI10I2OLZT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING MODE FUNCTION"
      ],
      "metadata": {
        "id": "RtLerXR9idTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def my_mode(sample):\n",
        "  return Counter(sample).most_common(1)[0][0]"
      ],
      "metadata": {
        "id": "9MMPitHsOLMz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fpygQvH3ifYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CALCULATING MODE OF PREDICTED OUTPUT"
      ],
      "metadata": {
        "id": "weSGfiklij6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mode\n",
        "\n",
        "cval = [0 for i in range(len(y_test))]\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  k=[y_p1[i],y_p2[i],y_p3[i],y_p4[i],y_p5[i],y_p6[i]]\n",
        "\n",
        "  cval[i]=my_mode(k)"
      ],
      "metadata": {
        "id": "AuAFfYTqOLHj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERATING CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "rYdAW2Hhioch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(cval)):\n",
        "    if (cval[i] == 0):\n",
        "        cval[i] = 'None'\n",
        "\n",
        "print(cval)\n",
        "y_actual = pd.Series(y_test, name='Actual')\n",
        "y_pred = pd.Series(cval, name='Predicted')\n",
        "confmat = pd.crosstab(y_actual, y_pred)\n",
        "print(confmat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zzmxPkonOLBN",
        "outputId": "229ba9f7-4d8a-4c34-ff5f-9811cd0970e7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0]\n",
            "Predicted  1.0  2.0  3.0  4.0\n",
            "Actual                       \n",
            "1.0          2   14  135    0\n",
            "2.0          1   20  149    3\n",
            "3.0          4   30  152    4\n",
            "4.0          3   20  144    2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINDING ACCURACY"
      ],
      "metadata": {
        "id": "PWW3N3pEipuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confmat = np.asarray(confmat)\n",
        "Acc = (confmat[0][0] + confmat[1][1] + confmat[2][2])/sum(sum(confmat))\n",
        "Acc1 = confmat[0][0]/sum(confmat[0])\n",
        "Acc2 = confmat[1][1]/sum(confmat[1])\n",
        "Acc3 = confmat[2][2]/sum(confmat[2])\n",
        "Acc4 = confmat[3][3]/sum(confmat[3])\n",
        "print('Overall Accuracy : ' + str(Acc))\n",
        "print('Accuracy of class 1 : ' + str(Acc1))\n",
        "print('Accuracy of class 2 : ' + str(Acc2))\n",
        "print('Accuracy of class 3 : ' + str(Acc3))\n",
        "print('Accuracy of class 4 : ' + str(Acc4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lTk6y-uyOKyo",
        "outputId": "4f15d075-4a65-4a0b-9412-0c06f2a3b9bb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy : 0.2547584187408492\n",
            "Accuracy of class 1 : 0.013245033112582781\n",
            "Accuracy of class 2 : 0.11560693641618497\n",
            "Accuracy of class 3 : 0.8\n",
            "Accuracy of class 4 : 0.011834319526627219\n"
          ]
        }
      ]
    }
  ]
}