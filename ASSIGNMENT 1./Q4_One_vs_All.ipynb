{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q4_One vs All.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q4 ONE VS ALL"
      ],
      "metadata": {
        "id": "7oGcBJ2jpv_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MOUNTING THE DRIVE"
      ],
      "metadata": {
        "id": "E0o_G3qiQHlG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WBVQlpGTn8EK",
        "outputId": "656eb039-eef1-4a2a-8a62-7d13a3cf7564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing libraries"
      ],
      "metadata": {
        "id": "pXgzmRG9QJeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "zeN-dAzfoAz9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "qw3RMHZlolfe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING SIGMOID FUNCTION"
      ],
      "metadata": {
        "id": "48SuGdDHQOIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  x = x.astype(float)\n",
        "  z = np.exp(-x)\n",
        "  sig = 1 / (1 + z)\n",
        "  return sig\n"
      ],
      "metadata": {
        "id": "PZsVPtp7omEJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING SET FUNCTION"
      ],
      "metadata": {
        "id": "pqI65R1XQPpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set(y):\n",
        "    for i in range(len(y)):\n",
        "        if(y[i]>=0.5):\n",
        "            y[i] = 1\n",
        "        if(y[i]<0.5):\n",
        "            y[i] = 0\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "_g2WWLLQopIw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING GRADIENT DESCENT FUNCTIONS"
      ],
      "metadata": {
        "id": "dGCs5ZIaQUHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def batch_gradient_descent(X,y,w,alpha,iters):\n",
        "  \n",
        "  cost_history = np.zeros(iters) # cost function for each iteration\n",
        "  \n",
        "  #initalize our cost history list to store the cost function on every iteration\n",
        "  \n",
        "  for i in range(iters):\n",
        "    z = np.dot(X,w.T)\n",
        "    hypothesis = sigmoid(z)\n",
        "    w = w -  alpha * np.dot((hypothesis-y), X) #weight updation\n",
        "  \n",
        "  return w"
      ],
      "metadata": {
        "id": "ngyYUnBHouRJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_gradient_descent_l1(X,y,w,alpha,iters,lamb):\n",
        "  \n",
        "  cost_history = np.zeros(iters) # cost function for each iteration\n",
        "  \n",
        "  #initalize our cost history list to store the cost function on every iteration\n",
        "  \n",
        "  for i in range(iters):\n",
        "    z = np.dot(X,w.T)\n",
        "    hypothesis = sigmoid(z)\n",
        "    w = w -  alpha * np.dot((hypothesis-y), X) - ((alpha*lamb/2)*np.sign(w))#weight updation\n",
        "  \n",
        "  return w"
      ],
      "metadata": {
        "id": "YZpod32zL5e5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_gradient_descent_l2(X,y,w,alpha,iters,lamb):\n",
        "  \n",
        "  cost_history = np.zeros(iters) # cost function for each iteration\n",
        "  \n",
        "  #initalize our cost history list to store the cost function on every iteration\n",
        "  \n",
        "  for i in range(iters):\n",
        "    z = np.dot(X,w.T)\n",
        "    hypothesis = sigmoid(z)\n",
        "    w = w*(1-alpha*lamb) -  alpha * np.dot((hypothesis-y), X) #weight updation\n",
        "  \n",
        "  return w"
      ],
      "metadata": {
        "id": "M0p9TROKL5W0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING THE DATA"
      ],
      "metadata": {
        "id": "hTYagarmQWkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/drive/MyDrive/nnfl data/data.xlsx',header=None)"
      ],
      "metadata": {
        "id": "SWm-bod0o0t9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datan=data.values\n",
        "X=datan[:,0:datan.shape[1]-1]\n",
        "y=datan[:,datan.shape[1]-1]\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GJYJBCYRuMLM",
        "outputId": "97053782-fb20-475f-b855-6f06be8bc3b2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3412, 61)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPLITTING THE DATA INTO TRAINING, VALIDATION AND TESTING using holdout validation"
      ],
      "metadata": {
        "id": "XyhfmbfcQZf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle = True, random_state = 8)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.125, shuffle = True, random_state = 8)\n"
      ],
      "metadata": {
        "id": "Cf3v7ZALuPhB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOMRALISING TESTING AND TRAINING DATA, ADDING BIAS VECTOR"
      ],
      "metadata": {
        "id": "EvKpoN0kQeJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m=X_train.shape[0] \n",
        "n=X_test.shape[0]\n",
        "\n",
        "qq = np.ones([n, 1])\n",
        "\n",
        "xmin1 = np.min(X_test, axis = 0) \n",
        "xmax1 = np.max(X_test, axis = 0) \n",
        "\n",
        "X_test = (X_test- xmin1)/(xmax1-xmin1)\n",
        "\n",
        "X_test = np.append(qq,X_test, axis=1)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b1R7JfYnyQ9A",
        "outputId": "31b1e4a8-53a8-4d21-82c1-77f41b71c065"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(683, 61)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xmin = np.min(X_train, axis = 0) \n",
        "xmax = np.max(X_train, axis = 0) \n",
        "\n",
        "X_train = (X_train- xmin)/(xmax-xmin)\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uJGz880yySgi",
        "outputId": "56353ebc-35d7-49f2-b9fc-b85bee08d18c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.39328586 0.16654807 0.16214643 ... 0.23299547 0.81403191 0.93200908]\n",
            " [0.11627088 0.11346816 0.21845213 ... 0.15076686 0.67705128 0.63106166]\n",
            " [0.51419012 0.52397105 0.22901312 ... 0.46541911 0.83192827 0.79023879]\n",
            " ...\n",
            " [0.63425256 0.53253442 0.3768769  ... 0.64252927 0.71068596 0.75504019]\n",
            " [0.29051515 0.30674267 0.25506676 ... 0.3681679  0.877832   0.63315738]\n",
            " [0.56033294 0.29998019 0.37576393 ... 0.3886692  0.76985938 0.700262  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp = np.ones([m, 1])\n",
        "X_train = np.append(pp,X_train, axis=1) #Column of ones \n",
        "\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6z48yDiAyUmb",
        "outputId": "fed858c1-a31c-4cb6-ef7d-af48a9705fc7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.39328586 0.16654807 ... 0.23299547 0.81403191 0.93200908]\n",
            " [1.         0.11627088 0.11346816 ... 0.15076686 0.67705128 0.63106166]\n",
            " [1.         0.51419012 0.52397105 ... 0.46541911 0.83192827 0.79023879]\n",
            " ...\n",
            " [1.         0.63425256 0.53253442 ... 0.64252927 0.71068596 0.75504019]\n",
            " [1.         0.29051515 0.30674267 ... 0.3681679  0.877832   0.63315738]\n",
            " [1.         0.56033294 0.29998019 ... 0.3886692  0.76985938 0.700262  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAKING TRAINING MODELS FOR OVE VS ALL 4 CASES"
      ],
      "metadata": {
        "id": "N0xYnyZVQj4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1_tr = [1 for i in range(len(y_train))]\n",
        "y2_tr = [1 for i in range(len(y_train))]\n",
        "y3_tr = [1 for i in range(len(y_train))]\n",
        "y4_tr = [1 for i in range(len(y_train))]\n",
        "for i in range(len(y_train)):\n",
        "    if(y_train[i] != 1):\n",
        "        y1_tr[i] = 0\n",
        "    if(y_train[i] != 2):\n",
        "        y2_tr[i] = 0\n",
        "    if(y_train[i] != 3):\n",
        "        y3_tr[i] = 0\n",
        "    if(y_train[i] != 4):\n",
        "        y4_tr[i] = 0\n",
        "print(y4_tr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lKaFM1yfsjQ-",
        "outputId": "f0f2b6b1-faac-41f1-b09f-460a8958e24b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMETING ONE VS ALL FOR BATCH GRADIENT DESCENT MULTICLASS LOR"
      ],
      "metadata": {
        "id": "ZL2yWY-DQoXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha=0.0025\n",
        "iters=1000\n",
        "\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m1 = batch_gradient_descent(X_train,y1_tr,w,alpha,iters)\n",
        "y_p1 = np.dot(X_test,w_m1.T)\n",
        "y_p1 = set(y_p1)\n",
        "\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m2 = batch_gradient_descent(X_train,y2_tr,w,alpha,iters)\n",
        "y_p2 = np.dot(X_test,w_m2.T)\n",
        "y_p2 = set(y_p2)\n",
        "\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m3 = batch_gradient_descent(X_train,y3_tr,w,alpha,iters)\n",
        "y_p3 = np.dot(X_test,w_m3.T)\n",
        "y_p3 = set(y_p3)\n",
        "\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m4 = batch_gradient_descent(X_train,y4_tr,w,alpha,iters)\n",
        "y_p4 = np.dot(X_test,w_m4.T)\n",
        "y_p4 = set(y_p4)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XirYjxn2pBGc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cval = [0 for i in range(len(y_test))]\n",
        "for i in range(len(y_test)):\n",
        "    if (y_p1[i] == 1):\n",
        "        cval[i] = 1.0\n",
        "    if (y_p2[i] == 1):\n",
        "        cval[i] = 2.0\n",
        "    if (y_p3[i] == 1):\n",
        "        cval[i] = 3.0\n",
        "    if (y_p4[i] == 1):\n",
        "        cval[i] = 4.0\n"
      ],
      "metadata": {
        "id": "ykNoqEzkpD29"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERATING THE CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "R99etChTQxD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test, cval)\n",
        "\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sYImKbQ_sqHp",
        "outputId": "2a923f43-1db3-4a22-84d1-55d64307b735"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  8   2 143   8]\n",
            " [  6   0 136  25]\n",
            " [  6   0 158  15]\n",
            " [  9   3 149  15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINDING INDIVIDUAL CLASS ACCURACY AND OVERALL ACCURACY "
      ],
      "metadata": {
        "id": "_B_bRSldQz6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confmat = np.asarray(cm)\n",
        "Acc = (confmat[0][0] + confmat[1][1] + confmat[2][2])/sum(sum(confmat))\n",
        "Acc1 = confmat[0][0]/sum(confmat[0])\n",
        "Acc2 = confmat[1][1]/sum(confmat[1])\n",
        "Acc3 = confmat[2][2]/sum(confmat[2])\n",
        "Acc4 = confmat[3][3]/sum(confmat[3])\n",
        "print('Overall Accuracy : ' + str(Acc))\n",
        "print('Accuracy of class 1 : ' + str(Acc1))\n",
        "print('Accuracy of class 2 : ' + str(Acc2))\n",
        "print('Accuracy of class 3 : ' + str(Acc3))\n",
        "print('Accuracy of class 4 : ' + str(Acc4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JLL-gUg1ssL1",
        "outputId": "428a3c2d-aaf8-4aa5-e71d-1b15218c087a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy : 0.2430453879941435\n",
            "Accuracy of class 1 : 0.049689440993788817\n",
            "Accuracy of class 2 : 0.0\n",
            "Accuracy of class 3 : 0.88268156424581\n",
            "Accuracy of class 4 : 0.08522727272727272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMETING ONE VS ALL FOR BATCH GRADIENT DESCENT MULTICLASS LOR WITH L1"
      ],
      "metadata": {
        "id": "9hywymy4Q54H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha=0.0025\n",
        "iters=1000\n",
        "lamb=1\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m1 = batch_gradient_descent_l1(X_train,y1_tr,w,alpha,iters,lamb)\n",
        "y_p1 = np.dot(X_test,w_m1.T)\n",
        "y_p1 = set(y_p1)\n",
        "\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m2 = batch_gradient_descent_l1(X_train,y2_tr,w,alpha,iters,lamb)\n",
        "y_p2 = np.dot(X_test,w_m2.T)\n",
        "y_p2 = set(y_p2)\n",
        "\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m3 = batch_gradient_descent_l1(X_train,y3_tr,w,alpha,iters,lamb)\n",
        "y_p3 = np.dot(X_test,w_m3.T)\n",
        "y_p3 = set(y_p3)\n",
        "\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m4 = batch_gradient_descent_l1(X_train,y4_tr,w,alpha,iters,lamb)\n",
        "y_p4 = np.dot(X_test,w_m4.T)\n",
        "y_p4 = set(y_p4)\n",
        "\n"
      ],
      "metadata": {
        "id": "MQv-z4XPMNzy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cval = [0 for i in range(len(y_test))]\n",
        "for i in range(len(y_test)):\n",
        "    if (y_p1[i] == 1):\n",
        "        cval[i] = 1.0\n",
        "    if (y_p2[i] == 1):\n",
        "        cval[i] = 2.0\n",
        "    if (y_p3[i] == 1):\n",
        "        cval[i] = 3.0\n",
        "    if (y_p4[i] == 1):\n",
        "        cval[i] = 4.0"
      ],
      "metadata": {
        "id": "4oxc6xyaMiTM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERATING THE CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "syXqR2gEQ9NA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test, cval)\n",
        "\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0l6KTT7RMkM-",
        "outputId": "1e10f272-740c-449a-8f29-b1413e6f0bab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  9   2 144   6]\n",
            " [  6   0 137  24]\n",
            " [  6   1 157  15]\n",
            " [  8   3 153  12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINDING INDIVIDUAL CLASS ACCURACY AND OVERALL ACCURACY"
      ],
      "metadata": {
        "id": "9o4KSt3WQ_dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confmat = np.asarray(cm)\n",
        "Acc = (confmat[0][0] + confmat[1][1] + confmat[2][2])/sum(sum(confmat))\n",
        "Acc1 = confmat[0][0]/sum(confmat[0])\n",
        "Acc2 = confmat[1][1]/sum(confmat[1])\n",
        "Acc3 = confmat[2][2]/sum(confmat[2])\n",
        "Acc4 = confmat[3][3]/sum(confmat[3])\n",
        "print('Overall Accuracy : ' + str(Acc))\n",
        "print('Accuracy of class 1 : ' + str(Acc1))\n",
        "print('Accuracy of class 2 : ' + str(Acc2))\n",
        "print('Accuracy of class 3 : ' + str(Acc3))\n",
        "print('Accuracy of class 4 : ' + str(Acc4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9TedrzRSMlwp",
        "outputId": "fcc473ff-b54a-41f4-9883-3e0b926d9462"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy : 0.2430453879941435\n",
            "Accuracy of class 1 : 0.055900621118012424\n",
            "Accuracy of class 2 : 0.0\n",
            "Accuracy of class 3 : 0.8770949720670391\n",
            "Accuracy of class 4 : 0.06818181818181818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMETING ONE VS ALL FOR BATCH GRADIENT DESCENT MULTICLASS LOR WITH L1"
      ],
      "metadata": {
        "id": "cRir3FfQRFu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha=0.0025\n",
        "iters=1000\n",
        "lamb=1\n",
        "\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m1 = batch_gradient_descent_l2(X_train,y1_tr,w,alpha,iters,lamb)\n",
        "y_p1 = np.dot(X_test,w_m1.T)\n",
        "y_p1 = set(y_p1)\n",
        "\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m2 = batch_gradient_descent_l2(X_train,y2_tr,w,alpha,iters,lamb)\n",
        "y_p2 = np.dot(X_test,w_m2.T)\n",
        "y_p2 = set(y_p2)\n",
        "\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m3 = batch_gradient_descent_l2(X_train,y3_tr,w,alpha,iters,lamb)\n",
        "y_p3 = np.dot(X_test,w_m3.T)\n",
        "y_p3 = set(y_p3)\n",
        "\n",
        "w= np.zeros((X_train.shape[1])) ###weight initialization\n",
        "w_m4 = batch_gradient_descent_l2(X_train,y4_tr,w,alpha,iters,lamb)\n",
        "y_p4 = np.dot(X_test,w_m4.T)\n",
        "y_p4 = set(y_p4)\n"
      ],
      "metadata": {
        "id": "4u8xnQDIMyi8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cval = [0 for i in range(len(y_test))]\n",
        "for i in range(len(y_test)):\n",
        "    if (y_p1[i] == 1):\n",
        "        cval[i] = 1.0\n",
        "    if (y_p2[i] == 1):\n",
        "        cval[i] = 2.0\n",
        "    if (y_p3[i] == 1):\n",
        "        cval[i] = 3.0\n",
        "    if (y_p4[i] == 1):\n",
        "        cval[i] = 4.0"
      ],
      "metadata": {
        "id": "cDZLzPEkNSrX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERATING THE CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "o-Gk5SgURHh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test, cval)\n",
        "\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cc9M72n7NUMw",
        "outputId": "d7646170-c3ab-442c-c5f3-b3efd0522b3e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6   0 153   2]\n",
            " [  3   0 153  11]\n",
            " [  4   0 170   5]\n",
            " [  5   0 161  10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINDING INDIVIDUAL CLASS ACCURACY AND OVERALL ACCURACY"
      ],
      "metadata": {
        "id": "isWUN6oJRJ8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confmat = np.asarray(cm)\n",
        "Acc = (confmat[0][0] + confmat[1][1] + confmat[2][2])/sum(sum(confmat))\n",
        "Acc1 = confmat[0][0]/sum(confmat[0])\n",
        "Acc2 = confmat[1][1]/sum(confmat[1])\n",
        "Acc3 = confmat[2][2]/sum(confmat[2])\n",
        "Acc4 = confmat[3][3]/sum(confmat[3])\n",
        "print('Overall Accuracy : ' + str(Acc))\n",
        "print('Accuracy of class 1 : ' + str(Acc1))\n",
        "print('Accuracy of class 2 : ' + str(Acc2))\n",
        "print('Accuracy of class 3 : ' + str(Acc3))\n",
        "print('Accuracy of class 4 : ' + str(Acc4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vd_93l6dNV0X",
        "outputId": "cf70a13e-20bc-4c35-a41c-244487354fd1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy : 0.25768667642752563\n",
            "Accuracy of class 1 : 0.037267080745341616\n",
            "Accuracy of class 2 : 0.0\n",
            "Accuracy of class 3 : 0.9497206703910615\n",
            "Accuracy of class 4 : 0.056818181818181816\n"
          ]
        }
      ]
    }
  ]
}