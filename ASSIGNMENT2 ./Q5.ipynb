{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNFL_A2_Q5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKNHGofo-5Oy",
        "outputId": "08a70617-1d67-43f5-d1f7-a59e870b29c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing directory to the directory containing dataset\n",
        "%cd drive/MyDrive/NNFL data/Data_A2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLV4lox_--8s",
        "outputId": "0e9636a8-64d2-4248-e57c-8430d9aef284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NNFL data/Data_A2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T8nJVyy_NG9",
        "outputId": "2c63bf83-621b-4e46-ce09-9401fcebed85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 87\n",
            "-rw------- 1 root root   259 Apr 29 07:23 class_label.mat\n",
            "-rw------- 1 root root 70617 Apr 22 07:54 data55.xlsx\n",
            "-rw------- 1 root root 17039 Apr 29 07:25 data5.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "0EgDWGnb_SqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "aEUApvhb_UbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoidFuntion(Z):\n",
        "    return 1/(1+np.exp(-Z)),Z\n",
        "\n",
        "def relu(Z):\n",
        "    A = np.maximum(0,Z)\n",
        "    return (Z,A)\n",
        "\n",
        "def reluBack(dA, cache):\n",
        "    Z = cache\n",
        "    \n",
        "    dZ = np.array(dA, copy=True) \n",
        "    dZ[Z <= 0] = 0\n",
        "    \n",
        "    return dZ\n",
        "\n",
        "def sigmoidBack(dA, cache):\n",
        "    Z = cache\n",
        "    \n",
        "    s = 1/(1+np.exp(-Z))\n",
        "    dZ = dA * s * (1-s)\n",
        "\n",
        "    return dZ\n",
        "\n",
        "def initializeParams(layerDimensions, para, stack):\n",
        "    parameters = {}\n",
        "    L = len(layerDimensions)            \n",
        "    for l in range(1, L-1):\n",
        "        if(stack==False):\n",
        "            parameters['W' + str(l)] = np.random.randn(layerDimensions[l], layerDimensions[l-1])\n",
        "        else:\n",
        "            parameters['W' + str(l)] = para[l-1]['W1']\n",
        "        parameters['b' + str(l)] = np.zeros((layerDimensions[l], 1))\n",
        "    parameters['W' + str(L-1)] = np.random.randn(layerDimensions[L-1], layerDimensions[L-2])\n",
        "    parameters['b' + str(L-1)] = np.zeros((layerDimensions[L-1],1))\n",
        "    return parameters\n",
        "\n",
        "def linearForward(A, W, bias):\n",
        "    Z = np.dot(W, A) + bias\n",
        "    cache = (A, W, bias)\n",
        "    return Z, cache\n",
        "\n",
        "def linearActivationForward(A_prev, W, bias, activation):\n",
        "    \n",
        "    if(activation == \"sigmoid\"):\n",
        "        Z, linear_cache = linearForward(A_prev, W, bias)\n",
        "        A, activation_cache = sigmoidFuntion(Z)\n",
        "    \n",
        "    elif(activation == \"relu\"):\n",
        "        Z, linear_cache = linearForward(A_prev, W, bias)\n",
        "        A, activation_cache = relu(Z)\n",
        "        \n",
        "    cache = (linear_cache, activation_cache)\n",
        "    \n",
        "    return A, cache\n",
        "\n",
        "def forwardModelL(X, params):\n",
        "    caches = []\n",
        "    A = X\n",
        "    L = (len(params) //2)\n",
        "    for l in range(1, L):\n",
        "        A_prev = A \n",
        "        A, cache = linearActivationForward(A, params['W'+str(l)], params['b'+str(l)], \"sigmoid\")\n",
        "        caches.append(cache)\n",
        "    \n",
        "    AL, cache = linearActivationForward(A, params['W'+str(L)], params['b'+str(L)], \"sigmoid\")\n",
        "    caches.append(cache)\n",
        "\n",
        "    return AL,caches\n",
        "\n",
        "def costComputation(AL, Y):\n",
        "    m = Y.shape[1]\n",
        "    cost = -(1/m)*np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))\n",
        "    cost = np.squeeze(cost)\n",
        "    return cost\n",
        "\n",
        "def costComputationAutoencoder(AL, Y, parameters):\n",
        "    m = Y.shape[1]\n",
        "    cost = (1/(2*m))*np.sum(np.linalg.norm(AL-Y))\n",
        "    L = (len(parameters) //2)\n",
        "    \n",
        "    return cost\n",
        "\n",
        "def linearBack(dZ, cache):\n",
        "    A_prev, W, _ = cache\n",
        "    _, m = A_prev.shape\n",
        "\n",
        "    dW = (1/m)*np.dot(dZ, A_prev.T)\n",
        "    db = (1/m)*np.sum(dZ, axis=1, keepdims=True)\n",
        "    dAP = np.dot(W.T, dZ)\n",
        "   \n",
        "    return dAP, dW, db\n",
        "\n",
        "def linearActivationBack(dA, cache, activation):\n",
        "    linearCache, activationCache = cache\n",
        "    \n",
        "    if (activation == \"relu\"):\n",
        "        dZ = reluBack(dA, activationCache)\n",
        "        dAP, dW, db = linearBack(dZ, linearCache)\n",
        "        \n",
        "    elif (activation == \"sigmoid\"):\n",
        "        dZ = sigmoidBack(dA, activationCache)\n",
        "        dAP, dW, db = linearBack(dZ, linearCache)\n",
        "    \n",
        "    return dAP, dW, db\n",
        "\n",
        "def modelLBack(AL, Y, caches):\n",
        "    gradients = {}\n",
        "    L = len(caches) \n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) \n",
        "    \n",
        "    dAL = -(np.divide(Y,AL)-np.divide(1-Y,1-AL))\n",
        "    \n",
        "    current_cache = caches[L-1]\n",
        "    gradients[\"dA\" + str(L-1)], gradients[\"dW\" + str(L)], gradients[\"db\" + str(L)] = linearActivationBack(dAL, current_cache, \"sigmoid\")\n",
        "   \n",
        "    for l in reversed(range(L-1)):\n",
        "    \n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linearActivationBack(gradients[\"dA\"+str(l+1)],current_cache,\"sigmoid\")\n",
        "        gradients[\"dA\" + str(l)] = dA_prev_temp\n",
        "        gradients[\"dW\" + str(l + 1)] = dW_temp\n",
        "        gradients[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "    return gradients\n",
        "\n",
        "def updateParams(parameters, gradients, learning_rate):\n",
        "   \n",
        "    L = (len(parameters) //2)\n",
        "\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)]-learning_rate*grads[\"dW\"+str(l+1)]\n",
        "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]-learning_rate*grads[\"db\"+str(l+1)]\n",
        "  \n",
        "    return parameters\n",
        "\n",
        "def layerLModel(X, Y, layers_dims, num_iterations,stack, learning_rate = 0.1):\n",
        "\n",
        "    costs = []                        \n",
        " \n",
        "    parameters = initializeParams(layers_dims,para,stack)\n",
        "\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        AL, caches = forwardModelL(X,parameters)\n",
        "        \n",
        "        if(stack==True):\n",
        "            cost = costComputation(AL, Y)\n",
        "        else:\n",
        "            cost = costComputationAutoencoder(AL, Y, parameters)\n",
        "        \n",
        "        grads = modelLBack(AL,Y,caches)\n",
        "     \n",
        "        parameters = updateParams(parameters,grads,learning_rate)\n",
        "\n",
        "        if(i%100==0):\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "        costs.append(cost)\n",
        "    print(cost)\n",
        "                \n",
        "    return parameters, costs"
      ],
      "metadata": {
        "id": "gwQhXkrw_U52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel('/content/drive/MyDrive/NNFL data/Data_A2/data55.xlsx')\n",
        "\n",
        "row, col = dataset.shape\n",
        "feats = col - 1 \n",
        "\n",
        "# normalization\n",
        "dataset.loc[:, dataset.columns != feats] = (dataset.loc[:, dataset.columns != feats]-dataset.loc[:, dataset.columns != feats].mean(axis=0))/dataset.loc[:, dataset.columns != feats].std(axis=0)\n",
        "\n",
        "# spliting dataset into train test and val\n",
        "training_data, validation_data, testing_data = np.split(dataset.sample(frac=1),[int(0.7*len(dataset)), int(0.8*len(dataset))])\n",
        "\n",
        "training_data = np.array(training_data)\n",
        "validation_data = np.array(validation_data)\n",
        "testing_data = np.array(testing_data)\n",
        "training_data_X = training_data[:, :feats]\n",
        "training_data_y = training_data[:, feats]\n",
        "validation_data_X = validation_data[:, :feats]\n",
        "validation_data_y = validation_data[:, feats]\n",
        "testing_data_X = testing_data[:, :feats]\n",
        "testing_data_y = testing_data[:, feats]\n",
        "\n",
        "train_row, train_col = training_data_X.shape\n",
        "\n",
        "\n",
        "para = []\n",
        "lr= 0.005\n",
        "\n",
        "layerDemensions = [72,64,72]\n",
        "params, costs = layerLModel(training_data_X, training_data_y, layerDemensions, num_iterations=1000, stack = False, learning_rate=lr)\n",
        "paramsAE1 = params\n",
        "\n",
        "W1=paramsAE1['W1']\n",
        "b1=paramsAE1['b1']\n",
        "X_new,_=linearActivationForward(X.T,W1,b1,\"sigmoid\")\n",
        "X_new.shape\n",
        "\n",
        "\n",
        "layerDemensions = [64,16,64]\n",
        "params, costs = layerLModel(training_data_X, training_data_y, layerDemensions,num_iterations=1000,stack = False,learning_rate=lr)\n",
        "paramsAE2 = params\n",
        "\n",
        "W1 = paramsAE2['W1']\n",
        "b1 = paramsAE2['b1']\n",
        "X_new, _ =  linearActivationForward(X.T, W1, b1, \"sigmoid\")\n",
        "\n",
        "\n",
        "layerDemensions = [16,4,16]\n",
        "params, costs = layerLModel(training_data_X, training_data_y, layerDemensions, learning_rate=lr, num_iterations=1000, stack=False)\n",
        "paramsAE3= params\n",
        "\n",
        "\n",
        "para=[paramsCopy, paramsAE2, paramsAE3]\n",
        "\n",
        "layerDemensions = [72,64,16,4,1]\n",
        "params, costs = layerLModel(training_data_X, training_data_y, layerDemensions,num_iterations=10000, stack=True, learning_rate=0.125)\n",
        "\n",
        "p, l = forwardModelL(training_data_X, params)\n",
        "p = (p>0.5).astype(int)\n",
        "a = training_data_y-p\n",
        "a = np.sum((a!=0).astype(int))\n",
        "accuracy = (p.shape[1]-a)/p.shape[1]\n",
        "print('Testing Accuracy: ')\n",
        "metrics(p, data_testing_y)\n",
        "print()\n",
        "print('Validation Accuracy: ')\n",
        "metrics(p, data_validation_y)"
      ],
      "metadata": {
        "id": "VBBYZq0M_cPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}